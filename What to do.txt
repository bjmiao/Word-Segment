词典的格式化（完成）
读取已有词典（完成）
读取分词结果（完成）
对于一篇文章：
	添加到词典(完成）
	词典排序(完成）（怎么按拼音排？！）
	搜索文件夹中所有的文章(完成，用编号start-stop实现）
	添加分词结果（完成）
	统一加到新版词典(完成）
维护词典的版本信息（日期（完成），训练了哪些文章（记录URL））
检查URL是否重复（完成）
添加一篇单独的监督训练语料到.dic,.log文件
完成啦！！！！！



可能在记录Suf，Pre的时候需要把标点看做是None

怎么使文章的数字与字母成为一个分词结构（？）
In general，怎么看待数字，‘G20’等结构

文章的训练部分
	找一个比较官方的成语词典
	辅助UI的设计图(完成)
	记录修正结果，保存到x-std.txt（记得添上表头URL）
	记录训练了哪些文章(使用网站的url）
	记录训练的结果（便于和正确结果相比较 调整参数）

分词策略：
（1）动态规划，求最优的分数
（2）分数的确定（调试参数）
（3）低频词的阈值
（4）四字词语更有可能成为一个分词单位
（5）特殊规则（？）
（6）对数字的特殊对待